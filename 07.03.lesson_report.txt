7/3 강의 정리
데이터 전처리 방법(정제, 변환, 통합 등)
전처리: 원시데이터를 분석 전 처리해 품질 및 신뢰성을 올리는 과정
- 품질향상, 성능 최적화, 효율성과 신뢰성 향상
- 정제: 결측값/이상값 처리/수정
- 변환: 스케일링, 인코딩
- 통합/변형: 병합, 집계, 변형
반드시 정해진 과정이라는 것은 없음.

주로 외부에서 데이터수집 -> 정제과정이 필수 -> 활용을 목적으로 수집계획을 짜지 않기 때문

형식에 따른 데이터처리방법이 다름.

결측치 - 데이터 정제 및 협업, 설득을 위해 필요
1) MCAR: 완전 무작위 누락
2) MAR: 관측가능한 변수와 관련된 누락
3) MNAR: 자체변수와 관련된 누락
- 완벽한 구분을 확인하기에는 어려울 수 있음
- 데이터 입력 오류, 응답자의 미응답, 데이터의 수집과정의 오류

이상치 - 데이터 분포에서 벗어난 극단적인 값으로 분석과 모델성능에 영향을 줄 수 있음. 
          - 완전 배제보다는 분석을 하고 사고

데이터 변환 - 단위차이를 없애고 동일 스케일로 조정, 계산안정성 및 속도 향상
- 스케일링(범위 임의 조정)
- 표준화 (평균 0, 표준편차 1로 조정) : 주택가격 등
- 정규화 (특정범위로 변환) : 이미지 처리(픽셀값) 등

-> 특정값에 대한  의존치 등을 줄이는데 도움

- 데이터 인코딩
1) 레이블 인코딩: 범주형 데이터를 숫자(고유한 정수)로 변환, 순서가 없으면 오류있는 관계를 학습
2) 원-핫 인코딩: 범주형 데이터를 이진벡터로 변환, 범주간 순서없는 데이터에 유용
                      범주가 많으면 메모리 사용량이 많이 증가

- 날짜 및 시간 데이터
-> 형식변환: 문자열 데이터 타입 datetime 형식으로 만듬 
-> 추출: 원하는 형식만을 취득

데이터 통합 및 변형
- 데이터 합치기: 공통된 키나 인덱스로 결합(없으면 만들어서 부여)
- 데이터 집계 : 특정 열을 기준으로 요약 통계 계산 -> 높은 수준의 인사이트 제공
- 데이터 그룹화: 특정열을 기준으로 데이터 그룹화
- 데이터 변형(재구조화): 데이터요약 및 목적에 따른 재구성
- 데이터 피벗: 데이터프레임의 행과 열을 변환 -> 특정측면 강조

데이터전처리 advanced(필요시 사용)
- 파생 변수 생성: 새로운 변수 생성 -> 변수간 상호작용 및 새로운 정보추출해서 정보량 증가 ->특정변수에 대한 정보량 과다로 오류발생 가능성 존재
- 데이터 샘플링: 일부 데이터를 선택, 추출해서 모델링에 사용 -> 모집단 특성 대표, 분석 및 데이터 처리 시간/비용 감소
                       랜덤/층화 샘플링
-차원 축소기법: 고차원에서 저차원으로 변환해 복잡성 감소과정(변동성 최대한 보존), PCA t-SNE -> 무지성 사용시 원치 않는 데이터 등을 변수로 사용할 수 있음
 
데이터 전처리 최적화
전처리 작업 자동화: 반복작엄을 자동화
파이프라인 구축: 단계를 순차적으로 자동실행하게 만듬 
대용량데이터 처리: 시간 및 메모리 사용의 효율성을 위해 필요
1) 분산처리: Hadoop, Spark(프레임워크) 등 사용
2) 병렬처리: multiprocessing, Dask(라이브러리) 등 사용
3) 메모리관리: 타입 최적화, 청크 단위 처리
- 알고리즘 사용, 코딩 스타일 변환, 라이브러리(pandas, NumPy, Dask)활용

실습과제: kaggle 데이터를 선정 데이터 전처리 파이프라인 구축
적절한 전처리 시나리오(데이터나 결측값 발생 원인 분석, 논리적인 전개) 